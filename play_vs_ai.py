import torch
from agent.DQN import DQNAgent
from GomokuEnv.gomoku_env import GomokuEnv
import numpy as np

def print_board(board):
    symbols = {0: ".", 1: "X", -1: "O"}
    for row in board:
        print(" ".join(symbols[val] for val in row))

def play():
    board_size = 5
    agent = DQNAgent(board_size=board_size)
    env = GomokuEnv(board_size=board_size, win_length=4)

    # è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
    agent.q_network.load_state_dict(torch.load("models/gomoku_15x15.pth"))
    agent.q_network.eval()

    state = env.reset()
    done = False

    while not done:
        print_board(env.board)
        print("ä½ çš„å›åˆï¼ˆè¼¸å…¥ row colï¼Œä¾‹å¦‚ 1 2ï¼‰ï¼š")
        row, col = map(int, input().split())
        action = row * board_size + col

        # ç©å®¶ä¸‹æ£‹
        next_state, reward, done, info = env.step(action)
        if info.get("invalid_move"):
            print("ç„¡æ•ˆè½å­ï¼Œè«‹é‡è©¦ï¼")
            continue
        if done:
            print_board(env.board)
            print("ğŸ‰ ä½ è´äº†ï¼")
            break

        # AI ä¸‹æ£‹
        state = next_state
        valid_actions = [i for i in range(board_size**2) if state.flatten()[i] == 0]
        ai_action = agent.act(state, valid_actions, train=False)
        state, reward, done, info = env.step(ai_action)

        print(f"ğŸ¤– AI è½å­ï¼š({ai_action // board_size}, {ai_action % board_size})")
        if done:
            print_board(env.board)
            print("ğŸ’€ AI è´äº†...")
            break

if __name__ == "__main__":
    play()
